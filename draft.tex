%!TEX TS-program = xelatex
\documentclass[11pt]{article}

\usepackage[english]{babel}

\usepackage{amsmath,amssymb,amsfonts}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{stix2}
\usepackage[scaled]{helvet}
\usepackage[scaled]{inconsolata}

\usepackage{lastpage}

\usepackage{setspace}

\usepackage{ccicons}

\usepackage[hang,flushmargin]{footmisc}

\usepackage{geometry}

\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}

\usepackage{fancyhdr}
\renewcommand{\headrulewidth}{0pt}\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\makeatletter
\newcounter{tableno}
\newenvironment{tablenos:no-prefix-table-caption}{
  \caption@ifcompatibility{}{
    \let\oldthetable\thetable
    \let\oldtheHtable\theHtable
    \renewcommand{\thetable}{tableno:\thetableno}
    \renewcommand{\theHtable}{tableno:\thetableno}
    \stepcounter{tableno}
    \captionsetup{labelformat=empty}
  }
}{
  \caption@ifcompatibility{}{
    \captionsetup{labelformat=default}
    \let\thetable\oldthetable
    \let\theHtable\oldtheHtable
    \addtocounter{table}{-1}
  }
}
\makeatother

\usepackage{array}
\newcommand{\PreserveBackslash}[1]{\let\temp=\\#1\let\\=\temp}
\let\PBS=\PreserveBackslash

\usepackage[breaklinks=true]{hyperref}
\hypersetup{colorlinks,%
citecolor=blue,%
filecolor=blue,%
linkcolor=blue,%
urlcolor=blue}
\usepackage{url}

\usepackage{caption}
\setcounter{secnumdepth}{0}
\usepackage{cleveref}

\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
\else\Gin@nat@width\fi}
\makeatother
\let\Oldincludegraphics\includegraphics
\renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=\maxwidth]{#1}}

\usepackage{longtable}
\usepackage{booktabs}

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}

\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[3] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1 \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces\fi
  % set entry spacing
  \ifnum #2 > 0
  \setlength{\parskip}{#2\baselineskip}
  \fi
 }%
 {}
\usepackage{calc} % for \widthof, \maxof
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\maxof{\widthof{#1}}{\csllabelwidth}}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth}{#1}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}\geometry{verbose,letterpaper,tmargin=2.2cm,bmargin=2.2cm,lmargin=2.2cm,rmargin=2.2cm}

\usepackage{lineno}
\usepackage[nolists,noheads]{endfloat}

\pagestyle{plain}

\tolerance=1
\emergencystretch=\maxdimen
\hyphenpenalty=10000
\hbadness=10000

\doublespacing

\fancypagestyle{normal}
{
  \fancyhf{}
  \fancyfoot[R]{\footnotesize\sffamily\thepage\ of \pageref*{LastPage}}
}
\begin{document}
\raggedright
\thispagestyle{empty}
{\Large\bfseries\sffamily Guidelines for the supervised learning of
species interactions}
\vskip 5em

%
\href{https://orcid.org/0000-0002-0735-5184}{Timothée\,Poisot}%
%
\,\textsuperscript{1,2}

\textsuperscript{1}\,Université de
Montréal\quad \textsuperscript{2}\,Québec Centre for Biodiversity
Sciences


\textbf{Correspondance to:}\\
Timothée Poisot --- \texttt{timothee.poisot@umontreal.ca}\\

\vfill
This work is released by its authors under a CC-BY 4.0 license\hfill\ccby\\
Last revision: \emph{\today}

\clearpage
\thispagestyle{empty}

\vfill

\begin{enumerate}
    \item The prediction of species interaction networks is gaining
momentum as a way to circumvent limitations in data volume. Yet,
ecological networks are challenging to predict because they are
typically small and sparse. Dealing with extreme class imbalance is a
challenge for most binary classifiers, and there are currently no
guidelines as to how predictive models can be trained.%
    \item Using simple mathematical arguments and numerical experiments
in which a variety of classifiers (for supervised learning) are trained
on simulated networks, we develop a series of guidelines related to the
choice of measures to use for model selection, and the degree of
unbiasing to apply to the training dataset.%
    \item Classifier accuracy and the ROC-AUC are not informative
measures for the performance of interaction prediction. PR-AUC is a
fairer assesment of performance. In some cases, even standard measures
can lead to selecting a more biased classifier because the effect of
connectance is strong. The amount of correction to apply to the training
dataset depends as a function of the classifier and the network
connectance.%
    \item These results reveal that training machines to predict
networks is a challenging task, and that in virtually all cases, the
composition of the training set needs to be experimented on before
performing the actual training. We discuss these consequences in the
context of the low volume of data.%
\end{enumerate}


\vfill

\clearpage
\linenumbers
\pagestyle{normal}

example on diagnostic test: rare events are hard to detect even with
really good models

summary of model challenges for networks - Strydom et al. (2021)
importance of drawing on traits + validation is challenging - Whalen et
al. (2021) machine learning from genomics

Binary classifiers are usually assessed by measuring properties of their
confusion matrix, \emph{i.e.} the contingency table reporting true/false
positive/negative hits. A confusion matrix is laid out as

\[\begin{pmatrix}
    \text{tp} & \text{fp} \\
    \text{fn} & \text{tn}
\end{pmatrix} \,,\]

wherein \(\text{tp}\) is the number of interactions predicted as
positive, \(\text{tn}\) is the number of non-interactions predicted as
negative, \(\text{fp}\) is the number of non-interactions predicted as
positive, and \(\text{fn}\) is the number of interactions predicted as
negative. Almost all measures based on the confusion matrix express
rates of error or success as proportions, and therefore the values of
these components matter in a \emph{relative} way. At a coarse scale, a
classifier is \emph{accurate} when the trace of the matrix divided by
the sum of the matrix is close to 1, with other measures focusing on
different ways in which the classifer is wrong.

The same approach is used to evaluate \emph{e.g.} species distribution
models (SDMs). Indeed, the training and evaluation of SDMs as binary
classifiers suffers from the same issue of low prevalence. In a previous
work, Allouche et al. (2006) suggested that \(\kappa\) was a better test
of model performance than the True Skill Statistic (TSS), which we will
refer to as Youden's informedness (or \(J\)); these conclusions were
later criticized by Somodi et al. (2017), who emphasized that
informedness' relationship to prevalence depends on assumptions about
bias in the model. Although this work offers recommendations about the
comparison of models, it doesn't establishes baselines or good practices
for training on imbalanced ecological data. Within the context of
networks, there are three specific issues that need to be adressed.
First, what values of performance measures are we expecting for a
classifier that has poor performance? This is particularly important as
it can evaluate whether low prevalence can lull us into a false sense of
predictive accuracy. Second, independently of the question of model
evaluation, is low prevalence an issue for \emph{training}, and can we
remedy it? Finally, because the low amount of data on interaction makes
a lot of imbalance correction methods (see \emph{e.g.} Branco et al.,
2015) hard to apply, which indicators can be optimized with the least
amount of positive interaction data?

We establish that due to the low prevalence of interactions, even poor
classifiers applied to food web data will reach a high accuracy; this is
because the measure is dominated by the accidental correct predictions
of negatives. The \(F_1\) score and positive predictive values are less
sensitive to bias, but \textbf{TODO}

Chicco et al. (2021) - MCC maximizes other measures, other measures do
not maximize MCC, except notably when prevalence is low, or the baseline
guessing level is uncertain, which applies to networks. In this cases,
informedness should be used as a maximization criterion. Formulating
guidelines is particularly important, because most of the litterature
existing on optimizing classifier performance in the life sciences is
focused on genomics applications (which has very specific challenges,
see a recent discussion by Whalen et al., 2021), and can give
contradictory recommendations (Boughorbel et al., 2017; Chicco \&
Jurman, 2020; Delgado \& Tibau, 2019). This points not to a defficiency
in the litterature, but rather to a need for domain-specific evaluation
of how the particular ways in which datasets are biased can affect the
performance of predictive models.

\hypertarget{baseline-values}{%
\section{Baseline values}\label{baseline-values}}

\hypertarget{confusion-matrix-with-skill-and-bias}{%
\subsection{Confusion matrix with skill and
bias}\label{confusion-matrix-with-skill-and-bias}}

In this section, we will assume a network of connectance \(\rho\),
\emph{i.e.} having \(\rho S^2\) interactions (where \(S\) is the species
richness), and \((1-\rho) S^2\) non-interactions. Therefore, the vector
describing the \emph{true} state of the network is a column vector
\(\mathbf{o}^T = [\rho (1-\rho)]\) (we can safely drop the \(S^2\)
terms, as we will work on the confusion matrix, which ends up expressing
\emph{relative} values).

In order to write the values of the confusion matrix for a hypothetical
classifier, we need to define two characteristics: its skill, and its
bias. Skill, here, refers to the propensity of the classifier to get the
correct answer (\emph{i.e.} to assign interactions where they are, and
to not assign them where they are not). A no-skill classifier guesses at
random, \emph{i.e.} it will guess interactions with a probability
\(\rho\). The predictions of a no-skill classifier can be expressed as a
row vector \(\mathbf{p} = [\rho (1-\rho)]\). The confusion matrix
\(\mathbf{M}\) for a no-skill classifier is given by the element-wise
product of these vectors \(\mathbf{o} \odot \mathbf{p}\), \emph{i.e.}

\[
\mathbf{M} = \begin{pmatrix}
    \rho^2 & \rho (1-\rho) \\
    (1-\rho) \rho & (1-\rho)^2
\end{pmatrix} \,.
\]

In order to regulate the skill of this classifier, we can define a skill
matrix \(\mathbf{S}\) with diagonal elements equal to \(s\), and
off-diagonal elements equal to \((1-s)\), and re-express the
skill-adjusted confusion matrix as \(\mathbf{M} \odot \mathbf{S}\),
\emph{i.e.}

\[
\begin{pmatrix}
    \rho^2 & \rho (1-\rho) \\
    (1-\rho) \rho & (1-\rho)^2
\end{pmatrix} \odot \begin{pmatrix}
    s & (1-s) \\
    (1-s) & s
\end{pmatrix} \,.
\]

Note that when \(s=0\), \(\text{Tr}(\mathbf{M}) = 0\) (the classifier is
\emph{always} wrong), when \(s=0.5\), the classifier is no-skill and
guesses at random, and when \(s=1\), the classifier is perfect.

The second element we can adjust in this hypothetical classifier is its
bias, specifically its tendency to over-predict interactions. Like
above, we can do so by defining a bias matrix \(\mathbf{B}\), where
interactions are over-predicted with probability \(b\), and express the
final classifier confusion matrix as
\(\mathbf{M}\odot \mathbf{S}\odot \mathbf{B}\), \emph{i.e.}

\[
\begin{pmatrix}
    \rho^2 & \rho (1-\rho) \\
    (1-\rho) \rho & (1-\rho)^2
\end{pmatrix} \odot \begin{pmatrix}
    s & (1-s) \\
    (1-s) & s
\end{pmatrix} \odot \begin{pmatrix}
    b & b \\
    (1-b) & (1-b)
\end{pmatrix}\,.
\]

The final expression for the confusion matrix in which we can regulate
the skill and the bias is

\[
\mathbf{C} = \begin{pmatrix}
    s\times b\times \rho^2 & (1-s)\times b\times \rho (1-\rho) \\
    (1-s)\times (1-b)\times (1-\rho) \rho & s\times (1-b)\times (1-\rho)^2
\end{pmatrix} \,.
\]

In all further simulations, the confusion matrix \(\mathbf{C}\) is
transformed so that it sums to 1.

\hypertarget{what-are-the-baseline-values-of-performance-measures}{%
\subsection{What are the baseline values of performance
measures?}\label{what-are-the-baseline-values-of-performance-measures}}

In this section, we will change the values of \(b\) abd \(s\) for a
given value of \(\rho\), and see how the values of common performance
measures for binary classification are affected. Specifically, we will
focus on four quantities: the accuracy
(\((\text{tp}+\text{tn})/(\text{tp}+\text{tn}+\text{fp}+\text{fn})\)),
the \emph{balanced} accuracy
(\(\text{tp}/(2(\text{tp}+\text{fn}))+\text{tn}/(2(\text{tn}+\text{fp}))\)),
Youden's J
(\(\text{tp}/(\text{tp}+\text{fn})+\text{tn}/(\text{tn}+\text{fp})-1\)),
and the \(F_1\) score (\(2\text{tp}/(2\text{tp}+\text{fp}+\text{fn})\)).

\textbf{Justification} of why these 4

Assuming a no-skill unbiased classifier (\(s=0.5\), \emph{i.e.}
\(\mathbf{C}=\mathbf{M}\) after normalization), the accuracy is
\(\rho^2 + (1-\rho)^2\), the balanced accuracy is \(0.5\), Youden's J is
\(0\), and \(F_1=\rho\). In other words, given a connectance
\(\rho = 0.05\), we expect that a classifier guessing at random would
still achieve an accuracy of \(0.905\); for a connectance of
\(\rho = 0.01\), this accuracy \emph{increases} to over \(0.98\). In
other words, networks with fewer interactions have inherently higher
accuracy, because it is easy to predict the overwheling majority of
non-interactions right.

In order to examine how these values change w.r.t. the skill and bias,
we performed a grid exploration of the values of \(\text{logit}(s)\) and
\(\text{logit}(b)\) linearly from \(-10\) to \(10\), and visualize the
result for a connectance of \(\rho = 0.15\), which is within the range
of usually observed connectance values for empirical food webs.

\begin{figure}
\hypertarget{fig:bias}{%
\centering
\includegraphics{figures/changing-bias.png}
\caption{Consequences of changing the classifier skills (\(s\)) and bias
(\(s\)) for a connectance \(\rho=0.15\), on accuracy, \(F_1\), postive
predictive value, and \(\kappa\). Accuracy increases with skill, but
also increases when the bias tends towards estimating \emph{fewer}
interactions. The \(F_1\) score increases with skill but also increases
when the bias tends towards estimating \emph{more} interactions; PPV
behaves in the same way. Interestingly, \(\kappa\) responds as expected
to skill (being negative whenever \(s < 0.5\)), and peaks for values of
\(b \approx 0.5\); nevertheless, the value of bias for which \(\kappa\)
is maximized in \emph{not} \(b=0.5\), but instead increases with
classifier skill. In other words, at equal skill, maximizing \(\kappa\)
would lead to select a \emph{more} biased classifier.}\label{fig:bias}
}
\end{figure}

\hypertarget{are-the-measures-affected-by-connectance}{%
\subsection{Are the measures affected by
connectance?}\label{are-the-measures-affected-by-connectance}}

\begin{figure}
\hypertarget{fig:connectance}{%
\centering
\includegraphics{figures/changing-connectance.png}
\caption{TODO}\label{fig:connectance}
}
\end{figure}

\hypertarget{numerical-experiments}{%
\section{Numerical experiments}\label{numerical-experiments}}

In the following section, we will generate random networks, and train
four binary classifiers (as well as an ensemble model using the sum of
the outputs) on 30\% of the interaction data. Networks are generated by
picking random generality \(g\) and vulnerability \(v\) traits for
\(S = 200\) species uniformly on the unit interval, and assigning an
interaction from species \(i\) to species \(j\) if
\(0.2g_i-\xi \le v_j \le 0.2g_i+\xi\), where \(\xi\) is a constant
regulating the connectance of the networks, and varies uniformly in
\([5\times 10^{-3}, 10^{-1}]\). This model gives fully interval networks
that are close analogues to the niche model (Williams \& Martinez,
2000), but has the benefit of only relying on two features
(\(g_i, v_j\)), and having the exact same rule for all interactions. It
is, therefore, a simple case which most classifiers should be able to
learn.

The training sample is composed of 30\% of the \(4\times 10^4\) possible
entries in the network, \emph{i.e.} \(n=12000\). Out of these
interactions, we pick a proportion \(\nu\) (the training set bias) to be
positive, so that the training set has \(\nu n\) interactions, and
\((1-\nu) n\) non-interactions. We vary \(\nu\) uniformly in \(]0,1[\).
This allows to evaluate how the measures of binary classification
performance respond to artificially rebalanced dataset for a given
network connectance. Note that both \(\xi\) and \(\nu\) are sampled from
a distribution rather than being picked on a grid; this is because there
is no direct relationship between the value of \(\xi\) and the
connectance of the simulated network, and therefore the precise value of
\(\xi\) is not relevant for the analysis of the results.

The dataset used for numerical experiments is composed of 20000 such
\((\xi, \nu)\) pairs, on which four learners are trained: a decision
tree regressor, a boosted regression tree, a ridge regressor, and a
random forest regressor. All models were taken from the \texttt{MLJ.jl}
package (Blaom et al., 2020; Blaom \& Vollmer, 2020) in Julia 1.7
(Bezanson et al., 2017). In order to pick the best adjacency matrix for
a given learner, we performed a thresholding approach using 500 steps on
predictions from the testing set, and picking the threshold that
maximized Youden's informedness, which is usually the optimized target
for imbalanced classification. During the thresholding step, we measured
the area under the receiving-operator characteristic (ROC-AUC) and
precision-recall (PR-AUC) curves, as measures of overall performance
over the range of returned values. We report the ROC-AUC and PR-AUC, as
well as a suite of other measures as introduced in the next section, for
the best threshold. The ensemble model was generated by summing the
predictions of all component models on the testing set (ranged in
\([0,1]\)), then put through the same thresholding process. The complete
code to run the simulations is given as an appendix.

After the simulations were completed, we removed all runs (\emph{i.e.}
pairs of \(\xi\) and \(\nu\)) for which at least one of the following
conditions was met: the accuracy was 0, the true positive or true
negative rates were 0, the connectance was larger than 0.2. This removes
both the obviously failed model runs, and the networks that are more
densely connected compared to the connectance of empirical food webs
(and are therefore less difficult to predict, being less imbalanced).

\hypertarget{effect-of-training-set-bias-on-performance}{%
\subsection{Effect of training set bias on
performance}\label{effect-of-training-set-bias-on-performance}}

\hypertarget{required-amount-of-positives-to-get-the-best-performance}{%
\subsection{Required amount of positives to get the best
performance}\label{required-amount-of-positives-to-get-the-best-performance}}

\hypertarget{guidelines-for-prediction}{%
\section{Guidelines for prediction}\label{guidelines-for-prediction}}

\hypertarget{references}{%
\section*{References}\label{references}}
\addcontentsline{toc}{section}{References}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\hypertarget{ref-Allouche2006AssAcc}{}%
Allouche, O., Tsoar, A., \& Kadmon, R. (2006). Assessing the accuracy of
species distribution models: Prevalence, kappa and the true skill
statistic (TSS). \emph{Journal of Applied Ecology}, \emph{43}(6),
1223--1232. \url{https://doi.org/10.1111/j.1365-2664.2006.01214.x}

\leavevmode\hypertarget{ref-Bezanson2017JulFre}{}%
Bezanson, J., Edelman, A., Karpinski, S., \& Shah, V. (2017). Julia: A
Fresh Approach to Numerical Computing. \emph{SIAM Review}, \emph{59}(1),
65--98. \url{https://doi.org/10.1137/141000671}

\leavevmode\hypertarget{ref-Blaom2020MljJul}{}%
Blaom, A. D., Kiraly, F., Lienart, T., Simillides, Y., Arenas, D., \&
Vollmer, S. J. (2020). MLJ: A Julia package for composable machine
learning. \emph{Journal of Open Source Software}, \emph{5}(55), 2704.
\url{https://doi.org/10.21105/joss.02704}

\leavevmode\hypertarget{ref-Blaom2020FleMod}{}%
Blaom, A. D., \& Vollmer, S. J. (2020, December 31). \emph{Flexible
model composition in machine learning and its implementation in MLJ}.
\url{http://arxiv.org/abs/2012.15505}

\leavevmode\hypertarget{ref-Boughorbel2017OptCla}{}%
Boughorbel, S., Jarray, F., \& El-Anbari, M. (2017). Optimal classifier
for imbalanced data using Matthews Correlation Coefficient metric.
\emph{PloS One}, \emph{12}(6), e0177678.
\url{https://doi.org/10.1371/journal.pone.0177678}

\leavevmode\hypertarget{ref-Branco2015SurPre}{}%
Branco, P., Torgo, L., \& Ribeiro, R. (2015, May 13). \emph{A Survey of
Predictive Modelling under Imbalanced Distributions}.
\url{http://arxiv.org/abs/1505.01658}

\leavevmode\hypertarget{ref-Chicco2020AdvMat}{}%
Chicco, D., \& Jurman, G. (2020). The advantages of the Matthews
correlation coefficient (MCC) over F1 score and accuracy in binary
classification evaluation. \emph{BMC Genomics}, \emph{21}(1), 6.
\url{https://doi.org/10.1186/s12864-019-6413-7}

\leavevmode\hypertarget{ref-Chicco2021MatCor}{}%
Chicco, D., Tötsch, N., \& Jurman, G. (2021). The Matthews correlation
coefficient (MCC) is more reliable than balanced accuracy, bookmaker
informedness, and markedness in two-class confusion matrix evaluation.
\emph{BioData Mining}, \emph{14}, 13.
\url{https://doi.org/10.1186/s13040-021-00244-z}

\leavevmode\hypertarget{ref-Delgado2019WhyCoh}{}%
Delgado, R., \& Tibau, X.-A. (2019). Why Cohen's Kappa should be avoided
as performance measure in classification. \emph{PloS One}, \emph{14}(9),
e0222916. \url{https://doi.org/10.1371/journal.pone.0222916}

\leavevmode\hypertarget{ref-Somodi2017PreDep}{}%
Somodi, I., Lepesi, N., \& Botta‐Dukát, Z. (2017). Prevalence dependence
in model goodness measures with special emphasis on true skill
statistics. \emph{Ecology and Evolution}, \emph{7}(3), 863--872.
\url{https://doi.org/10.1002/ece3.2654}

\leavevmode\hypertarget{ref-Strydom2021RoaPre}{}%
Strydom, T., Catchen, M. D., Banville, F., Caron, D., Dansereau, G.,
Desjardins-Proulx, P., Forero-Muñoz, N. R., Higino, G., Mercier, B.,
Gonzalez, A., Gravel, D., Pollock, L., \& Poisot, T. (2021). A roadmap
towards predicting species interaction networks (across space and time).
\emph{Philosophical Transactions of the Royal Society B: Biological
Sciences}, \emph{376}(1837), 20210063.
\url{https://doi.org/10.1098/rstb.2021.0063}

\leavevmode\hypertarget{ref-Whalen2021NavPit}{}%
Whalen, S., Schreiber, J., Noble, W. S., \& Pollard, K. S. (2021).
Navigating the pitfalls of applying machine learning in genomics.
\emph{Nature Reviews Genetics}, 1--13.
\url{https://doi.org/10.1038/s41576-021-00434-9}

\leavevmode\hypertarget{ref-Williams2000SimRul}{}%
Williams, R., \& Martinez, N. (2000). Simple rules yield complex food
webs. \emph{Nature}, \emph{404}, 180--183.
\href{http://userwww.sfsu.edu/\%20}{http://userwww.sfsu.edu/}

\end{CSLReferences}

\end{document}
