using Statistics
using StatsFuns
using StatsBase
using DataFramesMeta
using Random
using Statistics
using MLJ
using DataFrames
using CSV: CSV
using Distributions

# Simulation suffix
_suffix = get(ENV, "SLURM_ARRAY_TASK_ID", "global")

# AUC
function âˆ«(x::Array{T}, y::Array{T}) where {T<:Number}
    S = zero(Float64)
    for i in 2:length(x)
        S += (x[i] - x[i - 1]) * (y[i] + y[i - 1]) * 0.5
    end
    return .-S
end

# Confusion matrix utilities
include(joinpath(@__DIR__, "confusionmatrix.jl"))

# Network generation function
L(x::T, y::T; r::T=0.1) where {T<:Number} = (x-r/2.0) â‰¤ y â‰¤ (x+r/2.0)  ? one(T) : zero(T)
function network(S, Î¾)
    infectivity = Beta(6.0, 8.0)
    resistance = Beta(2.0, 8.0)
    ğ±áµ¥ = sort(rand(infectivity, S))
    ğ±â‚• = sort(rand(resistance, S))
    ğ±â‚ = repeat(ğ±áµ¥; outer=length(ğ±â‚•))
    ğ±â‚‚ = repeat(ğ±â‚•; inner=length(ğ±áµ¥))
    ğ±â‚ƒ = abs.(ğ±â‚ .- ğ±â‚‚)
    ğ² = [L(ğ±â‚[i], ğ±â‚‚[i]; r=Î¾) for i in 1:(S*S)]
    #ğ± = table(hcat(ğ±â‚, ğ±â‚‚, ğ±â‚ƒ))
    ğ± = table(hcat(ğ±â‚, ğ±â‚‚))
    return (ğ±, ğ²)
end

# Prepare the results
results = [DataFrame(;
    breadth=Float64[],
    bias=Float64[],
    connectance=Float64[],
    model=Symbol[],
    measure=Symbol[],
    value=Float64[],
) for _thr in 1:Threads.nthreads()]

# these regression machines go brrr as f u c k
DecisionTree = @load DecisionTreeRegressor pkg = DecisionTree verbosity=0
RandomForest = @load RandomForestRegressor pkg = DecisionTree verbosity=0
BoostedRegressor = @load EvoTreeRegressor pkg = EvoTrees verbosity=0
KNNRegressor = @load KNNRegressor pkg = NearestNeighborModels verbosity=0

candidate_models = [
    Symbol("Decision tree") => DecisionTree(),
    :BRT => BoostedRegressor(),
    Symbol("Random Forest") => RandomForest(),
    :kNN => KNNRegressor(),
]

S = 100
_n_sims = 600
conditions_breadth = rand(_n_sims) .* 0.4 .+ 0.05
conditions_bias = rand(_n_sims) .* 0.98 .+ 0.01
conditions = hcat(conditions_breadth, conditions_bias)

Threads.@threads for i in 1:size(conditions, 1)
    breadth, bias = conditions[i, :]
    @info i, Threads.threadid(), breadth, bias

    ğ—, ğ² = network(S, breadth)
    _real_co = mean(ğ²)

    training_size = round(Int64, 0.5 * length(ğ²))
    n_positive = round(Int64, training_size * bias)
    idx_pos = sample(findall(iszero.(ğ²)), n_positive; replace=true)
    idx_neg = sample(findall(isone.(ğ²)), training_size - n_positive; replace=true)
    Iâ‚š = shuffle(vcat(idx_neg, idx_pos))
    Iâ‚’ = setdiff(eachindex(ğ²), Iâ‚š)

    # Tweak the testing set to have the correct connectance - this results in a SMALLER testing set
    _test_pos = sum(ğ²[Iâ‚’])
    _expected_neg = round(Int64, _test_pos/_real_co - _test_pos)
    _observed_neg = round(Int64, length(Iâ‚’)-sum(ğ²[Iâ‚’]))
    tst_neg = sample(findall(iszero.(ğ²[Iâ‚’])), max(_observed_neg - _expected_neg, 1); replace=true)
    deleteat!(Iâ‚’, sort(unique(tst_neg)))
    #

    m = []
    for candidate_model in candidate_models
        this_machine = machine(candidate_model.second, ğ—, ğ²)
        fit!(this_machine; rows=Iâ‚š)
        prediction = mean.(MLJ.predict(this_machine; rows=Iâ‚’))
        pr = prediction .- minimum(prediction)
        pr = pr ./ maximum(pr)
        push!(m, pr)

        # The prediction isn't clamped because we threshold it so who gives a shit
        thresholds = LinRange(minimum(prediction), maximum(prediction), 500)

        # Confusion matrix
        binobs = Bool.(ğ²[Iâ‚’])
        M = Vector{ConfusionMatrix}(undef, length(thresholds))
        for (i, Ï„) in enumerate(thresholds)
            binpred = prediction .>= Ï„
            tp = sum(binobs .& binpred)
            tn = sum(.!binobs .& .!binpred)
            fp = sum(.!binobs .& binpred)
            fn = sum(binobs .& .!binpred)
            M[i] = ConfusionMatrix(tp, tn, fp, fn)
        end
        ROCAUC = âˆ«(fpr.(M), tpr.(M))
        AUPRC = âˆ«(tpr.(M), ppv.(M))
        ğŒ = M[last(findmax(informedness.(M)))]
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), candidate_model.first, :ROCAUC, ROCAUC))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), candidate_model.first, :PRAUC, AUPRC))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), candidate_model.first, :CSI, csi(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), candidate_model.first, :BA, balanced(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), candidate_model.first, :ACC, accuracy(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), candidate_model.first, :INF, informedness(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), candidate_model.first, :PT, pt(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), candidate_model.first, :FDR, fdir(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), candidate_model.first, :FOR, fomr(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), candidate_model.first, :KAPPA, Îº(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), candidate_model.first, :TPR, tpr(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), candidate_model.first, :TNR, tnr(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), candidate_model.first, :FPR, fpr(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), candidate_model.first, :FNR, fnr(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), candidate_model.first, :PPV, ppv(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), candidate_model.first, :NPV, npv(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), candidate_model.first, :MKD, markedness(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), candidate_model.first, :F1, f1(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), candidate_model.first, :MCC, mcc(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), candidate_model.first, :postbias, (ğŒ.tp+ğŒ.fp)/(ğŒ.tp+ğŒ.fn)))
    end

    # Ensemble model
    begin
        prediction = mean(hcat(m...); dims=2)
        thresholds = LinRange(minimum(prediction), maximum(prediction), 500)


        # Confusion matrix
        binobs = Bool.(ğ²[Iâ‚’])
        M = Vector{ConfusionMatrix}(undef, length(thresholds))
        for (i, Ï„) in enumerate(thresholds)
            binpred = prediction .>= Ï„
            tp = sum(binobs .& binpred)
            tn = sum(.!binobs .& .!binpred)
            fp = sum(.!binobs .& binpred)
            fn = sum(binobs .& .!binpred)
            M[i] = ConfusionMatrix(tp, tn, fp, fn)
        end
        ROCAUC = âˆ«(fpr.(M), tpr.(M))
        AUPRC = âˆ«(tpr.(M), ppv.(M))
        ğŒ = M[last(findmax(informedness.(M)))]
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), :Ensemble, :ROCAUC, ROCAUC))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), :Ensemble, :PRAUC, AUPRC))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), :Ensemble, :CSI, csi(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), :Ensemble, :BA, balanced(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), :Ensemble, :ACC, accuracy(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), :Ensemble, :INF, informedness(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), :Ensemble, :PT, pt(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), :Ensemble, :FDR, fdir(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), :Ensemble, :FOR, fomr(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), :Ensemble, :KAPPA, Îº(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), :Ensemble, :TPR, tpr(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), :Ensemble, :TNR, tnr(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), :Ensemble, :FPR, fpr(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), :Ensemble, :FNR, fnr(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), :Ensemble, :PPV, ppv(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), :Ensemble, :NPV, npv(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), :Ensemble, :MKD, markedness(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), :Ensemble, :F1, f1(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), :Ensemble, :MCC, mcc(ğŒ)))
        push!(results[Threads.threadid()], (breadth, bias, mean(ğ²), :Ensemble, :postbias, (ğŒ.tp+ğŒ.fp)/(ğŒ.tp+ğŒ.fn)))
    end
end

CSV.write(joinpath(@__DIR__, "output_$(_suffix).csv"), vcat(results...))
