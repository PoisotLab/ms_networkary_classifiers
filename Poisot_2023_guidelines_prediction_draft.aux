\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{A primer on binary classifier evaluation}{4}{section*.1}\protected@file@percent }
\newlabel{a-primer-on-binary-classifier-evaluation}{{}{4}{A primer on binary classifier evaluation}{section*.1}{}}
\newlabel{a-primer-on-binary-classifier-evaluation@cref}{{}{[1][4][]4}}
\@writefile{toc}{\contentsline {section}{Baseline values for the threshold metrics}{6}{section*.2}\protected@file@percent }
\newlabel{baseline-values-for-the-threshold-metrics}{{}{6}{Baseline values for the threshold metrics}{section*.2}{}}
\newlabel{baseline-values-for-the-threshold-metrics@cref}{{}{[1][6][]6}}
\@writefile{toc}{\contentsline {subsection}{Confusion matrix with skill and bias}{7}{section*.3}\protected@file@percent }
\newlabel{confusion-matrix-with-skill-and-bias}{{}{7}{Confusion matrix with skill and bias}{section*.3}{}}
\newlabel{confusion-matrix-with-skill-and-bias@cref}{{}{[1][7][]7}}
\@writefile{toc}{\contentsline {subsection}{What are the baseline values of performance measures?}{8}{section*.4}\protected@file@percent }
\newlabel{what-are-the-baseline-values-of-performance-measures}{{}{8}{What are the baseline values of performance measures?}{section*.4}{}}
\newlabel{what-are-the-baseline-values-of-performance-measures@cref}{{}{[1][8][]8}}
\@writefile{toc}{\contentsline {section}{Numerical experiments on training strategy}{10}{section*.5}\protected@file@percent }
\newlabel{numerical-experiments-on-training-strategy}{{}{10}{Numerical experiments on training strategy}{section*.5}{}}
\newlabel{numerical-experiments-on-training-strategy@cref}{{}{[1][9][]10}}
\@writefile{toc}{\contentsline {subsection}{Effect of training set balance on performance}{12}{section*.6}\protected@file@percent }
\newlabel{effect-of-training-set-balance-on-performance}{{}{12}{Effect of training set balance on performance}{section*.6}{}}
\newlabel{effect-of-training-set-balance-on-performance@cref}{{}{[1][12][]12}}
\@writefile{toc}{\contentsline {subsection}{Required amount of positives to get the best performance}{13}{section*.7}\protected@file@percent }
\newlabel{required-amount-of-positives-to-get-the-best-performance}{{}{13}{Required amount of positives to get the best performance}{section*.7}{}}
\newlabel{required-amount-of-positives-to-get-the-best-performance@cref}{{}{[1][13][]13}}
\@writefile{toc}{\contentsline {section}{Do better classification accuracy result in more realistic networks?}{14}{section*.8}\protected@file@percent }
\newlabel{do-better-classification-accuracy-result-in-more-realistic-networks}{{}{14}{Do better classification accuracy result in more realistic networks?}{section*.8}{}}
\newlabel{do-better-classification-accuracy-result-in-more-realistic-networks@cref}{{}{[1][14][]14}}
\gdef \LT@i {\LT@entry 
    {1}{64.9949pt}\LT@entry 
    {1}{48.28085pt}\LT@entry 
    {1}{48.28085pt}\LT@entry 
    {1}{43.74501pt}\LT@entry 
    {1}{48.28085pt}\LT@entry 
    {1}{48.28085pt}\LT@entry 
    {1}{48.28085pt}\LT@entry 
    {1}{48.28085pt}\LT@entry 
    {1}{48.28085pt}\LT@entry 
    {1}{42.28085pt}}
\newlabel{tbl:comparison}{{1}{15}{Do better classification accuracy result in more realistic networks?}{table.1}{}}
\newlabel{tbl:comparison@cref}{{[table][1][]1}{[1][15][]15}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Values of four performance metrics, and five network structure metrics, for 500 independent predictions similar to the ones presented in fig.~\ref {fig:ecovalid}. The values in \textbf  {bold} indicate the best value for each column (including ties). Because the values have been rounded, values of 1.0 for the ROC-AUC column indicate an average \(\ge 0.99\).\relax }}{15}{table.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Guidelines for the assessment of network predictive models}{16}{section*.9}\protected@file@percent }
\newlabel{guidelines-for-the-assessment-of-network-predictive-models}{{}{16}{Guidelines for the assessment of network predictive models}{section*.9}{}}
\newlabel{guidelines-for-the-assessment-of-network-predictive-models@cref}{{}{[1][16][]16}}
\newlabel{references}{{}{19}{References}{section*.10}{}}
\newlabel{references@cref}{{}{[1][19][]19}}
\@writefile{toc}{\contentsline {section}{References}{19}{section*.10}\protected@file@percent }
\newlabel{LastPage}{{}{24}{}{page.24}{}}
\xdef\lastpage@lastpage{24}
\xdef\lastpage@lastpageHy{24}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Consequences of changing the classifier skills (\(s\)) and bias (\(s\)) for a connectance \(\rho =0.15\), on \(F_1\), informedness, MCC, and \(\kappa \). Accuracy increases with skill, but also increases when the bias tends towards estimating \emph  {fewer} interactions (this follows from the derivations in the text, not shown in the figure). Interestingly, \(\kappa \) responds as expected to skill (being negative whenever \(s < 0.5\)), and peaks for values of \(b \approx 0.5\); nevertheless, the value of bias for which \(\kappa \) is maximized in \emph  {not} \(b=0.5\), but instead increases with classifier skill. In other words, at equal skill, maximizing \(\kappa \) would lead to select a \emph  {more} biased classifier.\relax }}{25}{figure.caption.11}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:bias}{{1}{25}{Consequences of changing the classifier skills (\(s\)) and bias (\(s\)) for a connectance \(\rho =0.15\), on \(F_1\), informedness, MCC, and \(\kappa \). Accuracy increases with skill, but also increases when the bias tends towards estimating \emph {fewer} interactions (this follows from the derivations in the text, not shown in the figure). Interestingly, \(\kappa \) responds as expected to skill (being negative whenever \(s < 0.5\)), and peaks for values of \(b \approx 0.5\); nevertheless, the value of bias for which \(\kappa \) is maximized in \emph {not} \(b=0.5\), but instead increases with classifier skill. In other words, at equal skill, maximizing \(\kappa \) would lead to select a \emph {more} biased classifier.\relax }{figure.caption.11}{}}
\newlabel{fig:bias@cref}{{[figure][1][]1}{[1][25][]25}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces As in fig.~\ref {fig:bias}, consequences of changing connectance for different levels of classifier skill, assuming no classifier bias. Informedness, \(\kappa \), and MCC do increase with connectance, but only when the classifier is not no-skill; by way of contrast, a more connected network will give a higher \(F_1\) value even with a no-skill classifier.\relax }}{26}{figure.caption.12}\protected@file@percent }
\newlabel{fig:connectance}{{2}{26}{As in fig.~\ref {fig:bias}, consequences of changing connectance for different levels of classifier skill, assuming no classifier bias. Informedness, \(\kappa \), and MCC do increase with connectance, but only when the classifier is not no-skill; by way of contrast, a more connected network will give a higher \(F_1\) value even with a no-skill classifier.\relax }{figure.caption.12}{}}
\newlabel{fig:connectance@cref}{{[figure][2][]2}{[1][26][]26}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Response of MCC, Informedness, ROC-AUC, and PR-AUC to changes in the training set balance (on the \(x\) axis) for a series of increasing connectances (color). All of these values approach 1 for a good model, but should be lower when the prediction is more difficult. Informedness is consistently high, and by contrast, MCC increases with additional training set balance. Across all models, training on a more connected network is easier. ROC-AUC is consistently high, and therefore not properly able to separate good from poor classifiers. On the other hand, PR-AUC responds to changes in the training set.\relax }}{27}{figure.caption.13}\protected@file@percent }
\newlabel{fig:biasco}{{3}{27}{Response of MCC, Informedness, ROC-AUC, and PR-AUC to changes in the training set balance (on the \(x\) axis) for a series of increasing connectances (color). All of these values approach 1 for a good model, but should be lower when the prediction is more difficult. Informedness is consistently high, and by contrast, MCC increases with additional training set balance. Across all models, training on a more connected network is easier. ROC-AUC is consistently high, and therefore not properly able to separate good from poor classifiers. On the other hand, PR-AUC responds to changes in the training set.\relax }{figure.caption.13}{}}
\newlabel{fig:biasco@cref}{{[figure][3][]3}{[1][27][]27}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Value of the optimal training set balance for the different models and measures evaluated here, over a range of connectances. Informedness was reliably maximized for balanced training sets, and kept this behavior across models. For other measures, larger connectances in the true network allowed lower biases in the training set. In a large number of cases, ``over-correcting'' by having training sets with more than half instances representing interactions would maximize the values of the model performance measures.\relax }}{28}{figure.caption.14}\protected@file@percent }
\newlabel{fig:optimbias}{{4}{28}{Value of the optimal training set balance for the different models and measures evaluated here, over a range of connectances. Informedness was reliably maximized for balanced training sets, and kept this behavior across models. For other measures, larger connectances in the true network allowed lower biases in the training set. In a large number of cases, ``over-correcting'' by having training sets with more than half instances representing interactions would maximize the values of the model performance measures.\relax }{figure.caption.14}{}}
\newlabel{fig:optimbias@cref}{{[figure][4][]4}{[1][28][]28}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces When trained on their optimally biased training set, most models were able to maximize their performance; this is not true when measuring PR-AUC for decision tree, k-NN, and to a lower extent RF. The ensemble had a consistently high performance despite incorporating low-performing models.\relax }}{29}{figure.caption.15}\protected@file@percent }
\newlabel{fig:optimvalue}{{5}{29}{When trained on their optimally biased training set, most models were able to maximize their performance; this is not true when measuring PR-AUC for decision tree, k-NN, and to a lower extent RF. The ensemble had a consistently high performance despite incorporating low-performing models.\relax }{figure.caption.15}{}}
\newlabel{fig:optimvalue@cref}{{[figure][5][]5}{[1][29][]29}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Visualisation of the raw (un-thresholded) models predictions for one instance of a network prediction problem (shown in the ``Dataset'' panel). Increasing the value of the \(\xi \) parameter would make the diagonal structure ``broader'', leading to more interactions. A visual inspection of the results is important, as it highlights how some models can ``miss'' parts of the network; by combining them in an ensemble, these gaps compensate one another, and lead (in this case) to a better prediction.\relax }}{30}{figure.caption.16}\protected@file@percent }
\newlabel{fig:ecovalid}{{6}{30}{Visualisation of the raw (un-thresholded) models predictions for one instance of a network prediction problem (shown in the ``Dataset'' panel). Increasing the value of the \(\xi \) parameter would make the diagonal structure ``broader'', leading to more interactions. A visual inspection of the results is important, as it highlights how some models can ``miss'' parts of the network; by combining them in an ensemble, these gaps compensate one another, and lead (in this case) to a better prediction.\relax }{figure.caption.16}{}}
\newlabel{fig:ecovalid@cref}{{[figure][6][]6}{[1][30][]30}}
\gdef \@abspage@last{30}
