\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{A primer on binary classifier evaluation}{5}{section*.1}\protected@file@percent }
\newlabel{a-primer-on-binary-classifier-evaluation}{{}{5}{A primer on binary classifier evaluation}{section*.1}{}}
\newlabel{a-primer-on-binary-classifier-evaluation@cref}{{}{[1][5][]5}}
\@writefile{toc}{\contentsline {section}{Baseline values for the threshold metrics}{7}{section*.2}\protected@file@percent }
\newlabel{baseline-values-for-the-threshold-metrics}{{}{7}{Baseline values for the threshold metrics}{section*.2}{}}
\newlabel{baseline-values-for-the-threshold-metrics@cref}{{}{[1][7][]7}}
\@writefile{toc}{\contentsline {subsection}{Confusion matrix with skill and bias}{7}{section*.3}\protected@file@percent }
\newlabel{confusion-matrix-with-skill-and-bias}{{}{7}{Confusion matrix with skill and bias}{section*.3}{}}
\newlabel{confusion-matrix-with-skill-and-bias@cref}{{}{[1][7][]7}}
\@writefile{toc}{\contentsline {subsection}{What are the baseline values of performance measures?}{8}{section*.4}\protected@file@percent }
\newlabel{what-are-the-baseline-values-of-performance-measures}{{}{8}{What are the baseline values of performance measures?}{section*.4}{}}
\newlabel{what-are-the-baseline-values-of-performance-measures@cref}{{}{[1][8][]8}}
\@writefile{toc}{\contentsline {section}{Numerical experiments on training strategy}{10}{section*.5}\protected@file@percent }
\newlabel{numerical-experiments-on-training-strategy}{{}{10}{Numerical experiments on training strategy}{section*.5}{}}
\newlabel{numerical-experiments-on-training-strategy@cref}{{}{[1][10][]10}}
\@writefile{toc}{\contentsline {subsection}{Effect of training set bias on performance}{12}{section*.6}\protected@file@percent }
\newlabel{effect-of-training-set-bias-on-performance}{{}{12}{Effect of training set bias on performance}{section*.6}{}}
\newlabel{effect-of-training-set-bias-on-performance@cref}{{}{[1][12][]12}}
\@writefile{toc}{\contentsline {subsection}{Required amount of positives to get the best performance}{13}{section*.7}\protected@file@percent }
\newlabel{required-amount-of-positives-to-get-the-best-performance}{{}{13}{Required amount of positives to get the best performance}{section*.7}{}}
\newlabel{required-amount-of-positives-to-get-the-best-performance@cref}{{}{[1][13][]13}}
\@writefile{toc}{\contentsline {section}{Do better classification accuracy result in more realistic networks?}{14}{section*.8}\protected@file@percent }
\newlabel{do-better-classification-accuracy-result-in-more-realistic-networks}{{}{14}{Do better classification accuracy result in more realistic networks?}{section*.8}{}}
\newlabel{do-better-classification-accuracy-result-in-more-realistic-networks@cref}{{}{[1][14][]14}}
\gdef \LT@i {\LT@entry 
    {3}{85.51878pt}\LT@entry 
    {1}{36.36372pt}\LT@entry 
    {3}{31.28293pt}\LT@entry 
    {1}{60.57413pt}\LT@entry 
    {1}{51.61705pt}\LT@entry 
    {1}{40.27287pt}\LT@entry 
    {3}{31.26103pt}\LT@entry 
    {3}{25.28293pt}}
\newlabel{tbl:comparison}{{1}{15}{Do better classification accuracy result in more realistic networks?}{table.1}{}}
\newlabel{tbl:comparison@cref}{{[table][1][]1}{[1][15][]15}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Values of four performance metrics, and three network structure metrics, for 250 independent predictions similar to the ones presented in fig.~\ref  {fig:ecovalid}. The values in \textbf  {bold} indicate the best value for each column (including ties). Because the values have been rounded, values of 1.0 for the ROC-AUC column indicate an average \(\ge 0.99\).\relax }}{15}{table.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Guidelines for the assesment of network predictive models}{15}{section*.9}\protected@file@percent }
\newlabel{guidelines-for-the-assesment-of-network-predictive-models}{{}{15}{Guidelines for the assesment of network predictive models}{section*.9}{}}
\newlabel{guidelines-for-the-assesment-of-network-predictive-models@cref}{{}{[1][15][]15}}
\newlabel{references}{{}{18}{References}{section*.10}{}}
\newlabel{references@cref}{{}{[1][18][]18}}
\@writefile{toc}{\contentsline {section}{References}{18}{section*.10}\protected@file@percent }
\newlabel{LastPage}{{}{21}{}{page.21}{}}
\xdef\lastpage@lastpage{21}
\xdef\lastpage@lastpageHy{21}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Consequences of changing the classifier skills (\(s\)) and bias (\(s\)) for a connectance \(\rho =0.15\), on accuracy, \(F_1\), postive predictive value, and \(\kappa \). Accuracy increases with skill, but also increases when the bias tends towards estimating \emph  {fewer} interactions. The \(F_1\) score increases with skill but also increases when the bias tends towards estimating \emph  {more} interactions; PPV behaves in the same way. Interestingly, \(\kappa \) responds as expected to skill (being negative whenever \(s < 0.5\)), and peaks for values of \(b \approx 0.5\); nevertheless, the value of bias for which \(\kappa \) is maximized in \emph  {not} \(b=0.5\), but instead increases with classifier skill. In other words, at equal skill, maximizing \(\kappa \) would lead to select a \emph  {more} biased classifier.\relax }}{22}{figure.caption.11}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:bias}{{1}{22}{Consequences of changing the classifier skills (\(s\)) and bias (\(s\)) for a connectance \(\rho =0.15\), on accuracy, \(F_1\), postive predictive value, and \(\kappa \). Accuracy increases with skill, but also increases when the bias tends towards estimating \emph {fewer} interactions. The \(F_1\) score increases with skill but also increases when the bias tends towards estimating \emph {more} interactions; PPV behaves in the same way. Interestingly, \(\kappa \) responds as expected to skill (being negative whenever \(s < 0.5\)), and peaks for values of \(b \approx 0.5\); nevertheless, the value of bias for which \(\kappa \) is maximized in \emph {not} \(b=0.5\), but instead increases with classifier skill. In other words, at equal skill, maximizing \(\kappa \) would lead to select a \emph {more} biased classifier.\relax }{figure.caption.11}{}}
\newlabel{fig:bias@cref}{{[figure][1][]1}{[1][22][]22}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces As in fig.~\ref  {fig:bias}, consequences of changing connectance for different levels of classifier skill, assuming no classifier bias. Informedness, \(\kappa \), and MCC do increase with connectance, but only when the classifier is not no-skill; by way of contrast, a more connected network will give a higher \(F_1\) value even with a no-skill classifier.\relax }}{23}{figure.caption.12}\protected@file@percent }
\newlabel{fig:connectance}{{2}{23}{As in fig.~\ref {fig:bias}, consequences of changing connectance for different levels of classifier skill, assuming no classifier bias. Informedness, \(\kappa \), and MCC do increase with connectance, but only when the classifier is not no-skill; by way of contrast, a more connected network will give a higher \(F_1\) value even with a no-skill classifier.\relax }{figure.caption.12}{}}
\newlabel{fig:connectance@cref}{{[figure][2][]2}{[1][23][]23}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Response of MCC and Informedness to changes in the training set bias for a fixed connectance (rows). Both of these values approach 1 for a good model. Informedness is consistently high, and by contrast, MCC increases with additional training set bias. Across all models, training on a more connected network is easier.\relax }}{24}{figure.caption.13}\protected@file@percent }
\newlabel{fig:biasmccinf}{{3}{24}{Response of MCC and Informedness to changes in the training set bias for a fixed connectance (rows). Both of these values approach 1 for a good model. Informedness is consistently high, and by contrast, MCC increases with additional training set bias. Across all models, training on a more connected network is easier.\relax }{figure.caption.13}{}}
\newlabel{fig:biasmccinf@cref}{{[figure][3][]3}{[1][24][]24}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Response of ROC-AUC and PR-AUC to changes in the training set bias for a fixed connectance (rows). ROC-AUC is consistently high, and therefore not properly able to separate good from poor classifiers. On the other hand, PR-AUC responds to changes in the training set. As in fig.~\ref  {fig:biasmccinf}, training on more connected networks is easier.\relax }}{25}{figure.caption.14}\protected@file@percent }
\newlabel{fig:biasrocpr}{{4}{25}{Response of ROC-AUC and PR-AUC to changes in the training set bias for a fixed connectance (rows). ROC-AUC is consistently high, and therefore not properly able to separate good from poor classifiers. On the other hand, PR-AUC responds to changes in the training set. As in fig.~\ref {fig:biasmccinf}, training on more connected networks is easier.\relax }{figure.caption.14}{}}
\newlabel{fig:biasrocpr@cref}{{[figure][4][]4}{[1][25][]25}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Value of the optimal training set bias for the different models and measures evaluated here, over a range of connectances. Informedness was reliably maximized for balanced training sets, and kept this behavior across models. For other measures, larger connectances in the true network allowed lower biases in the training set. In a large number of cases, ``over-correcting'' by having training sets with more than half instances representing interactions would maximize the values of the model performance measures.\relax }}{26}{figure.caption.15}\protected@file@percent }
\newlabel{fig:optimbias}{{5}{26}{Value of the optimal training set bias for the different models and measures evaluated here, over a range of connectances. Informedness was reliably maximized for balanced training sets, and kept this behavior across models. For other measures, larger connectances in the true network allowed lower biases in the training set. In a large number of cases, ``over-correcting'' by having training sets with more than half instances representing interactions would maximize the values of the model performance measures.\relax }{figure.caption.15}{}}
\newlabel{fig:optimbias@cref}{{[figure][5][]5}{[1][26][]26}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces When trained on their optimally biased training set, most models were able to maximize their performance; this is not true for decision tree, which had a very low PR-AUC, and to some extent for ridge regression who had a slow increase with network connectance. The ensemble had a consistently high performance despite incorporating poor models.\relax }}{27}{figure.caption.16}\protected@file@percent }
\newlabel{fig:optimperf}{{6}{27}{When trained on their optimally biased training set, most models were able to maximize their performance; this is not true for decision tree, which had a very low PR-AUC, and to some extent for ridge regression who had a slow increase with network connectance. The ensemble had a consistently high performance despite incorporating poor models.\relax }{figure.caption.16}{}}
\newlabel{fig:optimperf@cref}{{[figure][6][]6}{[1][27][]27}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Visualisation of the models predictions for one instance of a network prediction problem (shown in the ``Dataset'' panel). This figure reveals how inspecting the details of the prediction is important: indeed, although the performance measures hint at the fact that ridge regression is mediocre, this figure reveals that it is making predictions that correspond to a network with an entirely different topology (namely, nested as opposed to diagonal).\relax }}{28}{figure.caption.17}\protected@file@percent }
\newlabel{fig:ecovalid}{{7}{28}{Visualisation of the models predictions for one instance of a network prediction problem (shown in the ``Dataset'' panel). This figure reveals how inspecting the details of the prediction is important: indeed, although the performance measures hint at the fact that ridge regression is mediocre, this figure reveals that it is making predictions that correspond to a network with an entirely different topology (namely, nested as opposed to diagonal).\relax }{figure.caption.17}{}}
\newlabel{fig:ecovalid@cref}{{[figure][7][]7}{[1][28][]28}}
\gdef \@abspage@last{28}
