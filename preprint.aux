\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\new@tpo@label[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\pgfsyspdfmark {pgfid1}{1864679}{46968573}
\@writefile{toc}{\contentsline {section}{\numberline {1}Baseline values}{3}{section.1}\protected@file@percent }
\newlabel{baseline-values}{{1}{3}{Baseline values}{section.1}{}}
\newlabel{baseline-values@cref}{{[section][1][]1}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Confusion matrix with skill and bias}{3}{subsection.1.1}\protected@file@percent }
\newlabel{confusion-matrix-with-skill-and-bias}{{1.1}{3}{Confusion matrix with skill and bias}{subsection.1.1}{}}
\newlabel{confusion-matrix-with-skill-and-bias@cref}{{[subsection][1][1]1.1}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}What are the baseline values of performance measures?}{4}{subsection.1.2}\protected@file@percent }
\newlabel{what-are-the-baseline-values-of-performance-measures}{{1.2}{4}{What are the baseline values of performance measures?}{subsection.1.2}{}}
\newlabel{what-are-the-baseline-values-of-performance-measures@cref}{{[subsection][2][1]1.2}{[1][4][]4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Consequences of changing the classifier skills (\(s\)) and bias (\(s\)) for a connectance \(\rho =0.15\), on accuracy, \(F_1\), postive predictive value, and \(\kappa \). Accuracy increases with skill, but also increases when the bias tends towards estimating \emph  {fewer} interactions. The \(F_1\) score increases with skill but also increases when the bias tends towards estimating \emph  {more} interactions; PPV behaves in the same way. Interestingly, \(\kappa \) responds as expected to skill (being negative whenever \(s < 0.5\)), and peaks for values of \(b \approx 0.5\); nevertheless, the value of bias for which \(\kappa \) is maximized in \emph  {not} \(b=0.5\), but instead increases with classifier skill. In other words, at equal skill, maximizing \(\kappa \) would lead to select a \emph  {more} biased classifier.\relax }}{5}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:bias}{{1}{5}{Consequences of changing the classifier skills (\(s\)) and bias (\(s\)) for a connectance \(\rho =0.15\), on accuracy, \(F_1\), postive predictive value, and \(\kappa \). Accuracy increases with skill, but also increases when the bias tends towards estimating \emph {fewer} interactions. The \(F_1\) score increases with skill but also increases when the bias tends towards estimating \emph {more} interactions; PPV behaves in the same way. Interestingly, \(\kappa \) responds as expected to skill (being negative whenever \(s < 0.5\)), and peaks for values of \(b \approx 0.5\); nevertheless, the value of bias for which \(\kappa \) is maximized in \emph {not} \(b=0.5\), but instead increases with classifier skill. In other words, at equal skill, maximizing \(\kappa \) would lead to select a \emph {more} biased classifier.\relax }{figure.caption.1}{}}
\newlabel{fig:bias@cref}{{[figure][1][]1}{[1][4][]5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces As in fig.~\ref  {fig:bias}, consequences of changing connectance for different levels of classifier skill, assuming no classifier bias. Informedness, \(\kappa \), and MCC do increase with connectance, but only when the classifier is not no-skill; by way of contrast, a more connected network will give a higher \(F_1\) value even with a no-skill classifier.\relax }}{5}{figure.caption.2}\protected@file@percent }
\newlabel{fig:connectance}{{2}{5}{As in fig.~\ref {fig:bias}, consequences of changing connectance for different levels of classifier skill, assuming no classifier bias. Informedness, \(\kappa \), and MCC do increase with connectance, but only when the classifier is not no-skill; by way of contrast, a more connected network will give a higher \(F_1\) value even with a no-skill classifier.\relax }{figure.caption.2}{}}
\newlabel{fig:connectance@cref}{{[figure][2][]2}{[1][4][]5}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Numerical experiments on training strategy}{6}{section.2}\protected@file@percent }
\newlabel{numerical-experiments-on-training-strategy}{{2}{6}{Numerical experiments on training strategy}{section.2}{}}
\newlabel{numerical-experiments-on-training-strategy@cref}{{[section][2][]2}{[1][4][]6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Effect of training set bias on performance}{6}{subsection.2.1}\protected@file@percent }
\newlabel{effect-of-training-set-bias-on-performance}{{2.1}{6}{Effect of training set bias on performance}{subsection.2.1}{}}
\newlabel{effect-of-training-set-bias-on-performance@cref}{{[subsection][1][2]2.1}{[1][6][]6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces TODO\relax }}{7}{figure.caption.3}\protected@file@percent }
\newlabel{fig:biasmccinf}{{3}{7}{TODO\relax }{figure.caption.3}{}}
\newlabel{fig:biasmccinf@cref}{{[figure][3][]3}{[1][7][]7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Required amount of positives to get the best performance}{7}{subsection.2.2}\protected@file@percent }
\newlabel{required-amount-of-positives-to-get-the-best-performance}{{2.2}{7}{Required amount of positives to get the best performance}{subsection.2.2}{}}
\newlabel{required-amount-of-positives-to-get-the-best-performance@cref}{{[subsection][2][2]2.2}{[1][7][]7}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces TODO\relax }}{8}{figure.caption.4}\protected@file@percent }
\newlabel{fig:biasrocpr}{{4}{8}{TODO\relax }{figure.caption.4}{}}
\newlabel{fig:biasrocpr@cref}{{[figure][4][]4}{[1][7][]8}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces TODO\relax }}{8}{figure.caption.5}\protected@file@percent }
\newlabel{fig:optimbias}{{5}{8}{TODO\relax }{figure.caption.5}{}}
\newlabel{fig:optimbias@cref}{{[figure][5][]5}{[1][7][]8}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces TODO\relax }}{9}{figure.caption.6}\protected@file@percent }
\newlabel{fig:optimperf}{{6}{9}{TODO\relax }{figure.caption.6}{}}
\newlabel{fig:optimperf@cref}{{[figure][6][]6}{[1][7][]9}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Do better classification accuracy result in more realistic networks?}{9}{section.3}\protected@file@percent }
\newlabel{do-better-classification-accuracy-result-in-more-realistic-networks}{{3}{9}{Do better classification accuracy result in more realistic networks?}{section.3}{}}
\newlabel{do-better-classification-accuracy-result-in-more-realistic-networks@cref}{{[section][3][]3}{[1][9][]9}}
\gdef \LT@i {\LT@entry 
    {3}{71.35785pt}\LT@entry 
    {1}{32.02498pt}\LT@entry 
    {3}{27.84895pt}\LT@entry 
    {1}{51.92393pt}\LT@entry 
    {1}{44.56195pt}\LT@entry 
    {1}{35.23796pt}\LT@entry 
    {3}{27.83096pt}\LT@entry 
    {3}{21.84895pt}}
\gdef \FBLTpage@i {\gdef\flrow@LTlastpage{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces TODO\relax }}{10}{figure.caption.7}\protected@file@percent }
\newlabel{fig:ecovalid}{{7}{10}{TODO\relax }{figure.caption.7}{}}
\newlabel{fig:ecovalid@cref}{{[figure][7][]7}{[1][9][]10}}
\newlabel{tbl:comparison}{{1}{10}{Do better classification accuracy result in more realistic networks?}{table.1}{}}
\newlabel{tbl:comparison@cref}{{[table][1][]1}{[1][9][]10}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Values of four performance metrics, and three network structure metrics, for 250 independent predictions similar to the ones presented in fig.~\ref  {fig:ecovalid}. The values in \textbf  {bold} indicate the best value for each column (including ties). Because the values have been rounded, values of 1.0 for the ROC-AUC column indicate an average \(\ge 0.99\).\relax }}{10}{table.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Guidelines for the assesment of network predictive models}{10}{section.4}\protected@file@percent }
\newlabel{guidelines-for-the-assesment-of-network-predictive-models}{{4}{10}{Guidelines for the assesment of network predictive models}{section.4}{}}
\newlabel{guidelines-for-the-assesment-of-network-predictive-models@cref}{{[section][4][]4}{[1][10][]10}}
\newlabel{references}{{4}{11}{}{section.4}{}}
\newlabel{references@cref}{{[section][4][]4}{[1][11][]11}}
\@writefile{toc}{\contentsline {section}{References}{11}{section.4}\protected@file@percent }
\newlabel{LastPage}{{}{12}{}{page.12}{}}
\xdef\lastpage@lastpage{12}
\xdef\lastpage@lastpageHy{12}
\gdef \@abspage@last{12}
