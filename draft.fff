\begin{figure}
\hypertarget{fig:bias}{%
\centering
\includegraphics{figures/changing-bias.png}
\caption{Consequences of changing the classifier skills (\(s\)) and bias
(\(s\)) for a connectance \(\rho=0.15\), on \(F_1\), informedness, MCC,
and \(\kappa\). Accuracy increases with skill, but also increases when
the bias tends towards estimating \emph{fewer} interactions. The \(F_1\)
score increases with skill but also increases when the bias tends
towards estimating \emph{more} interactions. Interestingly, \(\kappa\)
responds as expected to skill (being negative whenever \(s < 0.5\)), and
peaks for values of \(b \approx 0.5\); nevertheless, the value of bias
for which \(\kappa\) is maximized in \emph{not} \(b=0.5\), but instead
increases with classifier skill. In other words, at equal skill,
maximizing \(\kappa\) would lead to select a \emph{more} biased
classifier.}\label{fig:bias}
}
\end{figure}
\efloatseparator
 
\begin{figure}
\hypertarget{fig:connectance}{%
\centering
\includegraphics{figures/changing-connectance.png}
\caption{As in fig.~\ref{fig:bias}, consequences of changing connectance
for different levels of classifier skill, assuming no classifier bias.
Informedness, \(\kappa\), and MCC do increase with connectance, but only
when the classifier is not no-skill; by way of contrast, a more
connected network will give a higher \(F_1\) value even with a no-skill
classifier.}\label{fig:connectance}
}
\end{figure}
\efloatseparator
 
\begin{figure}
\hypertarget{fig:biasco}{%
\centering
\includegraphics{figures/bias_by_connectance.png}
\caption{Response of MCC, Informedness, ROC-AUC, and PR-AUC to changes
in the training set balance (on the \(x\) axis) for a series of
increasing connectances (color). All of these values approach 1 for a
good model, but should be lower when the prediction is more difficult.
Informedness is consistently high, and by contrast, MCC increases with
additional training set balance. Across all models, training on a more
connected network is easier. ROC-AUC is consistently high, and therefore
not properly able to separate good from poor classifiers. On the other
hand, PR-AUC responds to changes in the training set.}\label{fig:biasco}
}
\end{figure}
\efloatseparator
 
\begin{figure}
\hypertarget{fig:optimbias}{%
\centering
\includegraphics{figures/optimal_bias.png}
\caption{Value of the optimal training set balance for the different
models and measures evaluated here, over a range of connectances.
Informedness was reliably maximized for balanced training sets, and kept
this behavior across models. For other measures, larger connectances in
the true network allowed lower biases in the training set. In a large
number of cases, ``over-correcting'' by having training sets with more
than half instances representing interactions would maximize the values
of the model performance measures.}\label{fig:optimbias}
}
\end{figure}
\efloatseparator
 
\begin{figure}
\hypertarget{fig:optimvalue}{%
\centering
\includegraphics{figures/optimal_value.png}
\caption{When trained on their optimally biased training set, most
models were able to maximize their performance; this is not true for
decision tree, k-NN, and to a lower extent RF. The ensemble had a
consistently high performance despite incorporating poor
models.}\label{fig:optimvalue}
}
\end{figure}
\efloatseparator
 
\begin{figure}
\hypertarget{fig:ecovalid}{%
\centering
\includegraphics{figures/valid_ensemble.png}
\caption{Visualisation of the raw (un-thresholded) models predictions
for one instance of a network prediction problem (shown in the
``Dataset'' panel). Increasing the value of the \(\xi\) parameter would
make the diagonal structure ``broader,'' leading to more interactions. A
visual inspection of the results is important, as it highlights how some
models can ``miss'' parts of the network; by combining them in an
ensemble, these gaps compensate one another, and lead (in this case) to
a better prediction.}\label{fig:ecovalid}
}
\end{figure}
